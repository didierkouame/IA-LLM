{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0379fe03-9895-463c-ad83-c185f5f902d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9107439f-77be-49a7-b319-cb532ec4368f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 14:52:27.605988: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738245147.625718   80082 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738245147.631736   80082 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-30 14:52:27.652688: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bc18fb7-2e9d-4cda-b7ba-b56a593b99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lire_fichier(chemin):\n",
    "    \"\"\" Lecture de fichier\"\"\"\n",
    "    fichier = open(chemin, encoding='utf-8')\n",
    "    chaine = fichier.read()\n",
    "    fichier.close()\n",
    "    return chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "66375533-e251-4346-8b63-503c9bab6a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger un modèle de Question Answering\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# charger le tokenizer et le modèle\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"timpal0l/mdeberta-v3-base-squad2\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"timpal0l/mdeberta-v3-base-squad2\")\n",
    "\n",
    "# sauvegarder en local\n",
    "tokenizer.save_pretrained(\"models/mdeberta-v3-base-squad2\")\n",
    "model.save_pretrained(\"models/mdeberta-v3-base-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf1d34cb-4d33-43bd-9650-c8b998e1565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouvrir le modele \n",
    "chemin_model = \"models/mdberta-v3-base-squad2/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(chemin_model)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(chemin_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0d6bdfb9-cf75-4279-8007-74d2cf5c05fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# pipeline\n",
    "from transformers import pipeline\n",
    "qa_model = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "589d2d1f-bc6a-4b1d-958a-f3e5fa166a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document : \n",
      "TALN_FR/101.pdf.tei.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Questions en cours de traitement:  50%|█████▌     | 1/2 [00:08<00:08,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse :   ceux liés au support des contraintes technologiques,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Questions en cours de traitement: 100%|███████████| 2/2 [00:16<00:00,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse :  l'apprentissage ludique de la langue amazighe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Étant donné qu'on a déjà travaillé sur les sections du corpus TALN-RECITAL \n",
    "# On reprend un document du même corpus\n",
    "# toujours sur les sections d'un document \n",
    "# De base les documents sont en .pdf\n",
    "# Pour trouver et extraire les sections d'un document on a utilisé GROBID qui est utile pour travailler sur des documents scientifiques bien structurés\n",
    "# Et on extrait le contenu des sections qui se trouvent entre des balises <div> </div>\n",
    "\n",
    "Documents = {}\n",
    "a = 0\n",
    "liste_fichiers = glob.glob(\"TALN_FR/101.pdf.tei.xml\") \n",
    "\n",
    "for chemin in liste_fichiers:\n",
    "    doc = Documents[chemin] = lire_fichier(chemin)\n",
    "    soup = BeautifulSoup(doc, 'html.parser')\n",
    "    toutes_sections = \"\"\n",
    "    a = 0\n",
    "    for cpt, bloc in enumerate(soup.find_all(\"div\")):\n",
    "        section = bloc.text\n",
    "        if len(section) < 100:\n",
    "            continue\n",
    "        toutes_sections += section + \"\\n\\n\" # concaténer les sections\n",
    "    print(\"Document : \")\n",
    "    print(chemin)\n",
    "    # stocker une liste de questions \n",
    "    questions = [\n",
    "        \"Quelles sont les missions principales de l'Institut Royal de la Culture Amazighe (IRCAM) ?\",\n",
    "        \"\"\"Quelle est la vocation de l'application \"Chiffres en Amazighe\" ?\"\"\",\n",
    "]\n",
    "    for question in tqdm(questions, desc=\"Questions en cours de traitement\"):\n",
    "        reponse = qa_model(question=question, context=toutes_sections)\n",
    "        print(\"Réponse : \", reponse['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0acd6810-5af8-4d41-afb6-e1f3b533f908",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TALN_FR/101.pdf.tei.xml', 'TALN_FR/968.pdf.tei.xml']\n"
     ]
    }
   ],
   "source": [
    "print(liste_fichiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1938d138-efb9-4a50-a71e-ac6ea7347561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ce9897-e7e1-40bc-b41b-b7843964c840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de2bd2b0-158f-45b1-a88e-371bef137ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b44c7-9f57-457e-856c-379dd3e550a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6049f3dc-a472-40d2-8ebb-028d7d5e4067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c7c166-3757-45c4-b683-22bfcb324a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
